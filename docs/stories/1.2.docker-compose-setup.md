# Story 1.2: Docker Compose Multi-Container Setup

## Status

Done

## Story

**As a** developer,
**I want** Docker Compose configured with 3 services (API, Agent, Data),
**so that** the entire system can run locally with a single `docker-compose up` command.

## Acceptance Criteria

1. `docker-compose.yml` defines 3 services: `api`, `agent`, `data`
2. `data` service runs PostgreSQL 15+ and Redis 7+
3. `api` service exposes port 8000 for webhook endpoints
4. `agent` service connects to Redis for pub/sub and PostgreSQL for data access
5. All services share a Docker network for inter-container communication
6. Environment variables loaded from `.env` file into containers
7. PostgreSQL data persists via Docker volume (survives container restart)
8. Redis configured with RDB persistence enabled (snapshots every 15 minutes)
9. Health checks configured for all 3 services
10. `docker-compose up` successfully starts all services without errors
11. Logs from all services visible via `docker-compose logs`

## Tasks / Subtasks

- [x] **Task 1: Create `docker-compose.yml` in project root** (AC: 1)
  - [x] Define Docker Compose version 3.8+ for compatibility
  - [x] Add `services` section with 3 services: `api`, `agent`, `data`
  - [x] Add shared network: `atrevete-network` (bridge driver)
  - [x] Add volume definitions: `postgres_data`, `redis_data`

- [x] **Task 2: Configure `data` service with PostgreSQL and Redis** (AC: 2, 7, 8)
  - [x] Use PostgreSQL 15+ official image (`postgres:15-alpine`)
  - [x] Map PostgreSQL port 5432 to host (for local development access)
  - [x] Create named volume `postgres_data` mounted to `/var/lib/postgresql/data`
  - [x] Set PostgreSQL environment variables: `POSTGRES_DB`, `POSTGRES_USER`, `POSTGRES_PASSWORD` from `.env`
  - [x] Use Redis 7+ official image (`redis:7-alpine`)
  - [x] Map Redis port 6379 to host (for local development access)
  - [x] Create named volume `redis_data` mounted to `/data`
  - [x] Configure Redis with RDB persistence via command: `redis-server --save 900 1 --save 300 10 --save 60 10000 --appendonly no`
  - [x] Attach both PostgreSQL and Redis containers to `atrevete-network`

- [x] **Task 3: Create Dockerfile for API service** (AC: 3, 6)
  - [x] Create `docker/Dockerfile.api` with Python 3.11-slim base image
  - [x] Set working directory to `/app`
  - [x] Copy `requirements.txt` and install dependencies with `pip install --no-cache-dir`
  - [x] Copy `/api` and `/shared` folders into container
  - [x] Expose port 8000
  - [x] Set CMD to run FastAPI with uvicorn: `uvicorn api.main:app --host 0.0.0.0 --port 8000`

- [x] **Task 4: Configure `api` service in docker-compose** (AC: 3, 4, 6, 9)
  - [x] Build from `docker/Dockerfile.api` context
  - [x] Map port 8000:8000 (host:container)
  - [x] Add `env_file: .env` to load environment variables
  - [x] Set `depends_on` with conditions: `data` service must be healthy before starting
  - [x] Attach to `atrevete-network`
  - [x] Configure health check: `curl -f http://localhost:8000/health || exit 1` (interval 30s, timeout 10s, retries 3)
  - [x] Set restart policy: `unless-stopped`

- [x] **Task 5: Create Dockerfile for Agent service** (AC: 4, 6)
  - [x] Create `docker/Dockerfile.agent` with Python 3.11-slim base image
  - [x] Set working directory to `/app`
  - [x] Copy `requirements.txt` and install dependencies with `pip install --no-cache-dir`
  - [x] Copy `/agent`, `/database`, and `/shared` folders into container
  - [x] Set CMD to run agent worker: `python -m agent.main`

- [x] **Task 6: Configure `agent` service in docker-compose** (AC: 4, 5, 6, 9)
  - [x] Build from `docker/Dockerfile.agent` context
  - [x] Add `env_file: .env` to load environment variables
  - [x] Set `depends_on` with conditions: `data` service must be healthy, `api` service must be healthy
  - [x] Attach to `atrevete-network`
  - [x] Configure health check: `python -c "import redis; r=redis.Redis(host='data', port=6379); r.ping()" || exit 1` (interval 30s, timeout 10s, retries 3)
  - [x] Set restart policy: `unless-stopped`

- [x] **Task 7: Configure health checks for `data` service** (AC: 9)
  - [x] PostgreSQL health check: `pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}` (interval 10s, timeout 5s, retries 5)
  - [x] Redis health check: `redis-cli ping` (interval 10s, timeout 5s, retries 5)
  - [x] Ensure health checks are defined using `healthcheck` key with `test`, `interval`, `timeout`, `retries` fields

- [x] **Task 8: Test complete Docker Compose setup** (AC: 10, 11)
  - [x] Run `docker-compose up -d` to start all services in detached mode
  - [x] Verify all 3 containers start without errors: `docker-compose ps` shows "Up" status
  - [x] Check PostgreSQL accessibility: `docker-compose exec data psql -U ${POSTGRES_USER} -d ${POSTGRES_DB} -c "SELECT 1"`
  - [x] Check Redis accessibility: `docker-compose exec data redis-cli ping`
  - [x] Verify API service health endpoint: `curl http://localhost:8000/health`
  - [x] View logs from all services: `docker-compose logs` (verify no critical errors)
  - [x] Test volume persistence: Create test data in PostgreSQL, restart containers, verify data survives
  - [x] Test network connectivity: Verify `api` and `agent` can reach `data` service by hostname

- [x] **Task 9: Create `.env.example` updates for Docker setup** (AC: 6)
  - [x] Add PostgreSQL connection string: `DATABASE_URL=postgresql+asyncpg://user:password@data:5432/atrevete_db`
  - [x] Add Redis connection string: `REDIS_URL=redis://data:6379/0`
  - [x] Add comment: "# For Docker Compose, use 'data' as hostname; for local dev outside Docker, use 'localhost'"
  - [x] Document all required environment variables for Story 0.1 integration

- [x] **Task 10: Write unit tests for Docker configuration** (AC: 10)
  - [x] Create `tests/integration/test_docker_setup.py`
  - [x] Test: Docker Compose file parses successfully (use `docker-compose config`)
  - [x] Test: All required services are defined (api, agent, data)
  - [x] Test: All required volumes are defined (postgres_data, redis_data)
  - [x] Test: Network is configured (atrevete-network)
  - [x] Test: Health checks are present for all services
  - [x] Use pytest with Docker SDK to validate configuration programmatically

## Dev Notes

### Previous Story Insights

No previous story exists. Story 1.2 is the second story in Epic 1 and assumes Story 1.1 (Project Structure & Dependency Setup) has been completed, providing the folder structure (`/api`, `/agent`, `/database`, `/shared`) and `requirements.txt`.

### Architecture Context

#### Multi-Container Architecture

**3-Service Design** [Source: architecture/high-level-architecture.md#24-high-level-architecture-diagram]
- **API Container**: FastAPI webhook receiver (port 8000)
- **Agent Container**: LangGraph orchestrator + background workers
- **Data Container**: PostgreSQL 15+ and Redis 7+ co-located

**Container Separation Rationale** [Source: architecture/high-level-architecture.md#21-technical-summary]
- API service requires high availability for webhook responsiveness (<3s response times)
- Agent service is long-running stateful process with LangGraph checkpointing
- Data service isolates persistence layer for backup/restore operations

#### Technology Versions

**Database Technologies** [Source: architecture/tech-stack.md#31-technology-stack-table]
- PostgreSQL: `15+` with JSONB, pg_trgm, timezone support
- Redis: `7.0+` with RDB persistence, pub/sub for messaging, TTL for state expiration

**Python & Framework Versions** [Source: architecture/tech-stack.md#31-technology-stack-table]
- Python: `3.11+` for async/await and type hints
- FastAPI: `0.116.1` with uvicorn standard
- Docker Compose: `2.20+` for multi-container orchestration

#### Docker Infrastructure

**IaC Tool** [Source: architecture/tech-stack.md#31-technology-stack-table]
- Docker Compose for multi-container orchestration
- Environment parity between dev/prod
- Simple deployment model (no Kubernetes overhead)

**Deployment Strategy** [Source: architecture/deployment-architecture.md#13-deployment-strategy]
- Target platform: VPS (Hetzner CPX21: 4GB RAM, 2 vCPU)
- HTTPS via Nginx reverse proxy (not included in this story)
- Daily PostgreSQL backups to object storage

#### Data Persistence Requirements

**PostgreSQL Persistence** [Source: architecture/high-level-architecture.md#24-high-level-architecture-diagram]
- 7 tables total (4 core + 3 transactional tables defined in Story 1.3a/1.3b)
- Volume-mounted storage: `/var/lib/postgresql/data`
- Must survive container restarts for booking data integrity

**Redis Persistence Configuration** [Source: architecture/tech-stack.md#31-technology-stack-table]
- RDB snapshots every 15 minutes (AC requirement)
- LangGraph checkpoints stored in Redis for crash recovery
- Pub/sub channels: `incoming_messages`, `outgoing_messages`, `payment_events`

#### Network Architecture

**Inter-Container Communication** [Source: architecture/high-level-architecture.md#25-architectural-patterns]
- Event-Driven Messaging: Redis Pub/Sub decouples API from Agent
- API → Redis: Enqueues webhook payloads
- Agent → Redis: Subscribes to message channels + checkpoint storage
- Agent → PostgreSQL: CRUD operations via SQLAlchemy
- All containers on shared Docker network for hostname resolution

#### Environment Configuration

**Environment Variable Strategy** [Source: architecture/coding-standards.md#181-critical-fullstack-rules]
- Access via `shared/config.py`, never direct `os.getenv()`
- `.env` file loaded by Docker Compose `env_file` directive
- Database hostname: `data` (Docker service name, not `localhost`)
- Connection strings must use async drivers: `postgresql+asyncpg://`, `redis://`

#### Health Check Requirements

**Service Health Validation** [Source: architecture/high-level-architecture.md#21-technical-summary]
- 99.5% uptime target requires container health monitoring
- PostgreSQL: `pg_isready` command
- Redis: `redis-cli ping` command
- API: FastAPI `/health` endpoint (Story 1.4 will implement this)
- Agent: Redis connectivity check (ping from Python)

### Project Structure Alignment

**Dockerfile Locations** [Source: architecture/unified-project-structure.md]
```
docker/
├── Dockerfile.api              # FastAPI container
├── Dockerfile.agent            # LangGraph + Workers container
├── docker-compose.yml          # Development 3-service setup
└── docker-compose.prod.yml     # Production (not in this story)
```

**Root-Level Files**
- `docker-compose.yml` should be in project root for convenience (`docker-compose up` from root)
- Dockerfiles in `/docker` folder for organization
- `.env` in root (loaded by docker-compose)

**Application Code Structure** [Source: architecture/unified-project-structure.md]
```
atrevete-bot/
├── api/                        # Copied to API container
│   ├── main.py                 # FastAPI entry point
│   ├── routes/
│   └── middleware/
├── agent/                      # Copied to Agent container
│   ├── main.py                 # Agent worker entry point
│   ├── graphs/
│   ├── nodes/
│   └── tools/
├── shared/                     # Copied to BOTH containers
│   ├── config.py               # Environment variable loader
│   ├── redis_client.py         # Redis singleton
│   └── constants.py
└── database/                   # Copied to Agent container (for ORM models)
    ├── models.py
    └── connection.py
```

### Connection String Examples

**PostgreSQL** (async driver for SQLAlchemy 2.0+)
```bash
DATABASE_URL=postgresql+asyncpg://user:password@data:5432/atrevete_db
```

**Redis** (for LangGraph checkpointer + pub/sub)
```bash
REDIS_URL=redis://data:6379/0
```

**Hostname Note**: Use `data` (Docker service name) not `localhost` when containers communicate

### Docker Compose Health Check Syntax

Health checks use the following format:
```yaml
healthcheck:
  test: ["CMD-SHELL", "command_here || exit 1"]
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 40s
```

### Redis RDB Configuration

RDB persistence command (no AOF for this story):
```bash
redis-server --save 900 1 --save 300 10 --save 60 10000 --appendonly no
```
- Save every 900s (15min) if ≥1 key changed
- Save every 300s (5min) if ≥10 keys changed
- Save every 60s if ≥10000 keys changed

### Dependencies Between Stories

**Prerequisite**: Story 1.1 must be completed
- Requires folder structure: `/api`, `/agent`, `/database`, `/shared`
- Requires `requirements.txt` with all dependencies listed

**Follow-on Stories**: Story 1.3a, 1.3b, 1.4, 1.5 will use this Docker setup
- Story 1.3a/1.3b: Alembic migrations run inside containers
- Story 1.4: API health endpoint implementation
- Story 1.5: Agent worker subscribes to Redis channels

### Testing

**Integration Test Approach** [Source: architecture/testing-strategy.md#152-test-organization]
- Mock external APIs (Google, Stripe, Chatwoot) — not needed for this story
- Real FastAPI + Redis for integration tests
- Docker SDK for programmatic Docker Compose validation

**Test File Location** [Source: architecture/testing-strategy.md#152-test-organization]
```
tests/
└── integration/
    └── test_docker_setup.py
```

**Test Requirements**
- Validate Docker Compose configuration parses correctly
- Ensure all required services, volumes, networks are defined
- Verify health checks are configured
- Use `pytest` with `docker` Python library

**Coverage Target** [Source: architecture/tech-stack.md#31-technology-stack-table]
- 85%+ overall coverage target (this story focuses on infrastructure, not code coverage)

### Security Considerations

**Environment Variable Security** [Source: architecture/coding-standards.md#181-critical-fullstack-rules]
- `.env` must be in `.gitignore` (Story 1.1 should have added this)
- Service account JSON keys should NEVER be committed
- PostgreSQL password should be strong (min 16 characters recommended)

**Container Security**
- Use official Alpine-based images for smaller attack surface
- No root user needed (PostgreSQL/Redis images run as non-root by default)
- Restart policy: `unless-stopped` (not `always`) to allow manual intervention

### Performance Considerations

**Resource Allocation** [Source: architecture/deployment-architecture.md#131-deployment-strategy]
- Target VPS: 4GB RAM, 2 vCPU
- PostgreSQL: ~512MB memory allocation (default, tunable later)
- Redis: ~256MB memory allocation (in-memory cache)
- API + Agent: Remaining ~3GB for Python processes

**Startup Dependencies**
- Use `depends_on` with `condition: service_healthy` to ensure ordered startup
- PostgreSQL must be ready before Agent starts (Alembic migrations in later stories)
- Redis must be ready before both API and Agent start

### Logging Strategy

**Docker Logs** [Source: architecture/tech-stack.md#31-technology-stack-table]
- Python logs to stderr → captured by Docker logs
- JSON-formatted logs (configured in later stories)
- View with `docker-compose logs -f <service_name>`

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-24 | 1.0 | Story created by Scrum Master (Bob) | Bob (SM Agent) |

## Dev Agent Record

### Agent Model Used

Claude Sonnet 4.5 (claude-sonnet-4-5-20250929)

### Debug Log References

None - No blocking issues encountered

### Completion Notes

- Successfully implemented 4-service Docker Compose architecture (postgres, redis, api, agent)
- Note: Story originally specified single "data" service running both PostgreSQL and Redis, but implemented as separate services per user clarification (not feasible with official images)
- All 11 integration tests passing
- Created minimal stub implementations for api/main.py and agent/main.py to enable Docker build and testing
- Updated .env.example with Docker-specific hostnames (postgres, redis instead of localhost)
- All services start healthy with proper dependency ordering and health checks
- Volume persistence verified through PostgreSQL restart test
- Network connectivity confirmed via health checks and service communication

### File List

**Created:**
- docker-compose.yml
- docker/Dockerfile.api
- docker/Dockerfile.agent
- api/main.py
- agent/main.py
- tests/integration/test_docker_setup.py

**Modified:**
- .env.example

## QA Results

*To be filled by QA agent*
