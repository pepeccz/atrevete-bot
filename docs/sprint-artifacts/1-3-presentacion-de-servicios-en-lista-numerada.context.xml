<story-context id=".bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>1</epicId>
    <storyId>3</storyId>
    <title>Presentaci√≥n de Servicios en Lista Numerada</title>
    <status>drafted</status>
    <generatedAt>2025-11-20</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/sprint-artifacts/1-3-presentacion-de-servicios-en-lista-numerada.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>cliente</asA>
    <iWant>ver los servicios disponibles en una lista numerada clara</iWant>
    <soThat>pueda seleccionar f√°cilmente el servicio que deseo</soThat>
    <tasks>
- [ ] Task 1: Actualizar prompts para listas numeradas de servicios (AC: 1, 3)
  - [ ] 1.1 Leer prompts actuales: `agent/prompts/step1_general.md` y `agent/prompts/step2_availability.md`
  - [ ] 1.2 Identificar secciones que presentan servicios
  - [ ] 1.3 Modificar instrucciones para formato lista numerada: "1. {nombre} ({duraci√≥n} min)"
  - [ ] 1.4 Agregar instrucci√≥n: m√°ximo 5 resultados por b√∫squeda
  - [ ] 1.5 Incluir ejemplo de formato esperado en prompt
  - [ ] 1.6 Verificar tono amigable y profesional en espa√±ol

- [ ] Task 2: Configurar truncaci√≥n en search_services tool (AC: 1)
  - [ ] 2.1 Revisar c√≥digo actual de `agent/tools/search_services.py`
  - [ ] 2.2 Verificar que max_results est√© configurado en 5
  - [ ] 2.3 Confirmar que output incluye nombre y duraci√≥n
  - [ ] 2.4 Si necesario, ajustar formato de output

- [ ] Task 3: Implementar parsing flexible de respuestas (AC: 2)
  - [ ] 3.1 Revisar c√≥mo el agente procesa respuestas de usuario
  - [ ] 3.2 Verificar que LLM puede identificar servicios por n√∫mero o nombre
  - [ ] 3.3 Agregar instrucci√≥n en prompt para aceptar ambos formatos
  - [ ] 3.4 Testear con ejemplos: "1", "opci√≥n 1", "corte", "el primero"

- [ ] Task 4: Testing de presentaci√≥n de servicios (AC: 1, 2, 3)
  - [ ] 4.1 Test manual: Solicitar servicios y verificar formato lista numerada
  - [ ] 4.2 Test manual: Responder con n√∫mero y verificar identificaci√≥n correcta
  - [ ] 4.3 Test manual: Responder con texto y verificar identificaci√≥n correcta
  - [ ] 4.4 Test manual: Verificar m√°ximo 5 resultados mostrados
  - [ ] 4.5 Test manual: Verificar tono amigable en espa√±ol

- [ ] Task 5: Documentar cambios en prompts (AC: 1, 3)
  - [ ] 5.1 Actualizar Dev Notes con formato de lista implementado
  - [ ] 5.2 Documentar ejemplos de respuestas aceptadas
  - [ ] 5.3 Agregar referencias a FRs cubiertos
    </tasks>
  </story>

  <acceptanceCriteria>
1. **AC1**: El agente presenta servicios en formato lista numerada con nombre y duraci√≥n
   - Given el cliente indica intenci√≥n de agendar cita
   - When el agente presenta servicios disponibles
   - Then se muestran en formato "1. {Servicio} ({duraci√≥n} min)"
   - And la lista contiene m√°ximo 5 resultados por b√∫squeda
   - And cada entrada es clara y legible

2. **AC2**: El sistema acepta respuestas por n√∫mero o texto descriptivo
   - Given el cliente responde a la lista de servicios
   - When el cliente responde con n√∫mero (ej: "1") o texto (ej: "corte")
   - Then el sistema identifica el servicio correcto
   - And procede al siguiente paso del flujo

3. **AC3**: La presentaci√≥n usa tono amigable y profesional en espa√±ol
   - Given el agente presenta la lista
   - When genera el mensaje
   - Then usa lenguaje natural amigable
   - And mantiene tono profesional
   - And todo el texto est√° en espa√±ol
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <!-- PRD: Requisitos funcionales de presentaci√≥n de servicios -->
      <doc>
        <path>docs/prd.md</path>
        <title>Product Requirements Document</title>
        <section>FR1, FR38, FR39 - Listas Numeradas y UX</section>
        <snippet>
          FR1: El sistema presenta servicios disponibles en lista numerada para facilitar selecci√≥n.
          FR38: Todas las selecciones de opciones usan listas numeradas.
          FR39: El sistema acepta respuestas por n√∫mero o por texto descriptivo.
        </snippet>
      </doc>

      <!-- Architecture: Optimizaciones v3.2 relevantes -->
      <doc>
        <path>docs/architecture.md</path>
        <title>System Architecture</title>
        <section>Tool Output Truncation (v3.2)</section>
        <snippet>
          search_services: Max 5 resultados, output simplificado (campo id removido).
          Estrategia de reducci√≥n de tokens en 60-70% mediante prompt caching y truncaci√≥n.
        </snippet>
      </doc>

      <!-- Epic Tech-Spec: Contexto t√©cnico del Epic 1 -->
      <doc>
        <path>docs/sprint-artifacts/tech-spec-epic-1.md</path>
        <title>Epic 1 Technical Specification</title>
        <section>Story 1.3 - Listas Numeradas</section>
        <snippet>
          Modificar prompts step1_service.md y step2_availability.md para formato lista numerada.
          No requiere cambios de c√≥digo Python - solo prompts.
          Testing manual conversacional, no unit tests automatizados.
        </snippet>
      </doc>
    </docs>

    <code>
      <!-- Prompt: Presentaci√≥n de servicios (PASO 1) -->
      <artifact>
        <path>agent/prompts/step1_service.md</path>
        <kind>prompt</kind>
        <symbol>PASO 1: Recolectar el Servicio</symbol>
        <lines>1-49</lines>
        <reason>Prompt actual que presenta servicios. Requiere actualizaci√≥n para formato lista numerada.</reason>
      </artifact>

      <!-- Prompt: Disponibilidad y estilistas (PASO 2) -->
      <artifact>
        <path>agent/prompts/step2_availability.md</path>
        <kind>prompt</kind>
        <symbol>PASO 2: Acordar Asistenta y Disponibilidad</symbol>
        <lines>19-34</lines>
        <reason>Prompt que presenta estilistas y horarios. Ya tiene formato numerado implementado (1A, 1B, 2A, 2B).</reason>
      </artifact>

      <!-- Tool: B√∫squeda de servicios con fuzzy matching -->
      <artifact>
        <path>agent/tools/search_services.py</path>
        <kind>tool</kind>
        <symbol>search_services</symbol>
        <lines>57-239</lines>
        <reason>Tool que retorna servicios. Ya configurado con max_results=5. No requiere modificaciones de c√≥digo.</reason>
      </artifact>

      <!-- Prompt Core: Reglas generales del bot -->
      <artifact>
        <path>agent/prompts/core.md</path>
        <kind>prompt</kind>
        <symbol>Maite - Core Identity</symbol>
        <lines>1-161</lines>
        <reason>Contiene reglas cr√≠ticas, personalidad, y estilo conversacional que deben mantenerse consistentes.</reason>
      </artifact>

      <!-- Testing: Test existente de booking tools como referencia -->
      <artifact>
        <path>tests/unit/test_booking_tools.py</path>
        <kind>test</kind>
        <symbol>test_booking_tools</symbol>
        <lines>all</lines>
        <reason>Referencia de estructura de tests unitarios. Esta story NO requiere unit tests (solo prompts).</reason>
      </artifact>
    </code>

    <dependencies>
      <python version="3.11+">
        <!-- LLM & Agent Framework -->
        <package name="langgraph" version=">=0.6.7"/>
        <package name="langchain" version=">=0.3.0"/>
        <package name="langchain-openai" version=">=0.3.0"/>

        <!-- Testing -->
        <package name="pytest" version=">=8.3.0"/>
        <package name="pytest-asyncio" version=">=0.24.0"/>

        <!-- LLM Gateway -->
        <package name="openai" version="Compatible con OpenRouter API"/>

        <!-- Note: Esta story solo modifica prompts, no tiene nuevas dependencias -->
      </python>
    </dependencies>
  </artifacts>

  <constraints>
    <!-- Arquitectura: Solo prompts, no c√≥digo Python -->
    <constraint type="architecture">
      Esta story modifica √öNICAMENTE archivos de prompts (.md). NO modificar c√≥digo Python.
      Archivos a modificar: agent/prompts/step1_service.md y agent/prompts/step2_availability.md
    </constraint>

    <!-- Tool existente: search_services ya configurado -->
    <constraint type="implementation">
      search_services tool ya configurado con max_results=5 y output simplificado (v3.2).
      NO requiere modificaciones de c√≥digo.
    </constraint>

    <!-- Tono y lenguaje: Mantener consistencia -->
    <constraint type="ux">
      Mantener tono amigable y profesional en espa√±ol seg√∫n core.md:
      - Mensajes concisos (2-4 frases, max 150 palabras)
      - Espa√±ol conversacional natural
      - Emojis: 1-2 m√°ximo (üå∏ saludos, üíï empat√≠a, üòä positivo)
      - Formato WhatsApp nativo: *negrita*, _cursiva_, listas con guiones
    </constraint>

    <!-- NFR1: Respuesta r√°pida -->
    <constraint type="performance">
      NFR1: Respuesta del bot &lt;5 segundos. Listas numeradas reducen tokens y latencia.
    </constraint>

    <!-- Prompt Caching: OpenRouter autom√°tico -->
    <constraint type="optimization">
      OpenRouter proporciona automatic prompt caching (&gt;1024 tokens) para cost optimization.
      Los prompts actualizados deben aprovechar este caching.
    </constraint>

    <!-- Testing: Solo manual -->
    <constraint type="testing">
      Esta story NO requiere unit tests automatizados (NFR10 no aplica).
      Testing manual conversacional v√≠a WhatsApp es suficiente.
    </constraint>
  </constraints>

  <interfaces>
    <!-- Tool: search_services - Interfaz existente -->
    <interface>
      <name>search_services</name>
      <kind>LangChain Tool</kind>
      <signature>
        async def search_services(
            query: str,
            category: Literal["Peluquer√≠a", "Est√©tica"] | None = None,
            max_results: int = 5
        ) -> dict[str, Any]
      </signature>
      <path>agent/tools/search_services.py</path>
      <notes>
        Returns: {"services": [...], "count": int, "query": str}
        Each service: {"name": str, "duration_minutes": int, "category": str, "match_score": int}
        LLM debe presentar estos servicios en formato lista numerada.
      </notes>
    </interface>

    <!-- LLM: GPT-4.1-mini via OpenRouter -->
    <interface>
      <name>OpenRouter API (GPT-4.1-mini)</name>
      <kind>LLM API</kind>
      <signature>ChatOpenAI configured for OpenRouter gateway</signature>
      <path>agent/nodes/conversational_agent.py</path>
      <notes>
        Model: openai/gpt-4.1-mini
        Capacidad natural de entender respuestas por n√∫mero o texto.
        No requiere c√≥digo adicional para parsing flexible.
      </notes>
    </interface>

    <!-- Prompt Loading: Modular state detection -->
    <interface>
      <name>_detect_booking_state()</name>
      <kind>Python Function</kind>
      <signature>def _detect_booking_state(state: ConversationState) -> str</signature>
      <path>agent/prompts/__init__.py</path>
      <notes>
        Detecta estado de booking (SERVICE_SELECTION, AVAILABILITY_CHECK, etc.)
        Carga prompts espec√≠ficos seg√∫n estado.
        step1_service.md se carga en SERVICE_SELECTION state.
      </notes>
    </interface>
  </interfaces>

  <tests>
    <standards>
      Esta story modifica solo prompts, por lo tanto:
      - ‚úÖ Testing manual conversacional (recomendado)
      - ‚ùå NO requiere unit tests automatizados
      - ‚úÖ Verificaci√≥n de formato y tono
      - Coverage m√≠nima de 85% (NFR10) NO aplica para prompts

      Framework de testing existente:
      - pytest 8.3.0+ con pytest-asyncio 0.24.0+
      - Testing manual v√≠a WhatsApp real o simulado
    </standards>

    <locations>
      <!-- No se crean nuevos archivos de tests para esta story -->
      tests/unit/ - No aplica (solo prompts)
      tests/integration/ - No aplica (solo prompts)

      Testing manual:
      - WhatsApp real: Interacci√≥n con bot en producci√≥n
      - Docker logs: docker-compose logs -f agent
    </locations>

    <ideas>
      <!-- AC1: Presentaci√≥n en lista numerada -->
      <test id="T1" maps-to="AC1">
        Tipo: Manual conversacional
        Input: "Quiero agendar una cita"
        Expected: Lista numerada con 5 servicios m√°ximo
        Verify: Formato "1. {Servicio} ({duraci√≥n} min)"
        Verify: Cada entrada clara y legible
      </test>

      <!-- AC2: Selecci√≥n por n√∫mero -->
      <test id="T2" maps-to="AC2">
        Tipo: Manual conversacional
        Input: "1" o "Opci√≥n 1" o "el primero"
        Expected: Sistema identifica servicio correctamente
        Verify: Procede a siguiente paso sin confusi√≥n
      </test>

      <!-- AC2: Selecci√≥n por texto -->
      <test id="T3" maps-to="AC2">
        Tipo: Manual conversacional
        Input: "Corte" o "Quiero el corte de caballero"
        Expected: Sistema identifica servicio por fuzzy match
        Verify: Procede correctamente al siguiente paso
      </test>

      <!-- AC3: Tono amigable en espa√±ol -->
      <test id="T4" maps-to="AC3">
        Tipo: Manual conversacional
        Verify: Mensajes en espa√±ol amigable y profesional
        Verify: No usa lenguaje rob√≥tico o excesivamente formal
        Verify: Emojis adecuados (1-2 m√°ximo)
        Verify: Formato WhatsApp nativo (*negrita*, listas con -)
      </test>

      <!-- Edge case: M√°ximo 5 resultados -->
      <test id="T5" maps-to="AC1">
        Tipo: Manual conversacional
        Input: "Servicios de corte"
        Expected: M√°ximo 5 servicios mostrados
        Verify: search_services tool respeta max_results=5
      </test>

      <!-- Comandos de testing manual -->
      <test id="T6" maps-to="ALL">
        # Verificar prompts actualizados
        cat agent/prompts/step1_service.md | grep -A 10 "lista numerada"
        cat agent/prompts/step2_availability.md | grep -A 10 "lista numerada"

        # Reiniciar agent para aplicar cambios en prompts
        docker-compose restart agent

        # Testing v√≠a WhatsApp
        # 1. Enviar: "Quiero una cita"
        # 2. Verificar formato de lista numerada
        # 3. Probar respuestas: "1", "corte", "el primero"
      </test>
    </ideas>
  </tests>
</story-context>