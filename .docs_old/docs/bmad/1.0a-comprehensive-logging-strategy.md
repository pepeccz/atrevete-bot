# BMAD: Comprehensive Logging Strategy

**Story:** Epic 1 - Foundation (all stories)
**Date:** 2025-10-28
**Severity:** Low (Positive improvement)
**Status:** ✅ Implemented and working

---

## Behavior

### Observed Implementation

During Epic 1 implementation, a comprehensive structured logging strategy was implemented across all services (API, Agent) without being specified in the original PRD or Architecture documents.

**Components**:
- Centralized logging configuration (`shared/logging_config.py`)
- JSON-structured log format
- Consistent log levels (DEBUG, INFO, WARNING, ERROR, CRITICAL)
- Context fields (timestamp, logger name, level)
- Per-module loggers using `logger = get_logger(__name__)`

**Example Output**:
```json
{"timestamp": "2025-10-27T23:01:01.698893+00:00", "level": "INFO", "logger": "__main__", "message": "Initializing AsyncRedisSaver"}
```

### Benefits

- **Epic 2+ Debugging**: Structured logs enable easy filtering/searching
- **Epic 6 Monitoring**: JSON format ready for log aggregation (ELK, Datadog)
- **Production Readiness**: Professional logging from day one
- **Troubleshooting**: BMAD 1.5a-1.5d heavily relied on logs for debugging

---

## Measure

### Before (Expected from Specs)

Original specifications did not detail logging strategy beyond basic print statements or default Python logging.

### After (Implemented)

**File**: `shared/logging_config.py`
```python
import logging
import json
from datetime import datetime, timezone

class JSONFormatter(logging.Formatter):
    def format(self, record):
        log_data = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
        }
        if record.exc_info:
            log_data["exception"] = self.formatException(record.exc_info)
        return json.dumps(log_data)

def get_logger(name):
    logger = logging.getLogger(name)
    if not logger.handlers:
        handler = logging.StreamHandler()
        handler.setFormatter(JSONFormatter())
        logger.addHandler(handler)
        logger.setLevel(logging.INFO)
    return logger
```

**Usage Pattern**:
```python
# api/main.py
from shared.logging_config import get_logger
logger = get_logger(__name__)

logger.info(f"API started on port {settings.API_PORT}")
logger.error(f"Database connection failed: {error}")
```

**Log Volume** (Epic 1 implementation):
- API logs: ~50 log statements
- Agent logs: ~80 log statements
- Shared logs: ~20 log statements

---

## Act

### Implementation Details

**Files Modified/Created**:
- `shared/logging_config.py` - Centralized logging setup
- `api/main.py` - API service logging
- `agent/main.py` - Agent service logging
- All tool files (`agent/tools/*.py`) - Tool operation logging
- All node files (`agent/nodes/*.py`) - Graph node logging

**Log Levels Used**:
- **DEBUG**: Detailed diagnostic info (disabled in production)
- **INFO**: General operational messages (startup, message received, API calls)
- **WARNING**: Unexpected but handled situations (retries, fallbacks)
- **ERROR**: Error conditions (API failures, database errors)
- **CRITICAL**: System failures (not yet used in Epic 1)

### Deployment

Logging was implemented incrementally during Epic 1 development:
1. Initial basic logging in Story 1.4 (API)
2. Enhanced during Story 1.5 (Agent)
3. Refined during BMAD debugging sessions (1.5a-1.5d)

---

## Document

### Lessons Learned

1. **Structured Logging from Day One**: Implementing JSON logging early paid dividends during debugging (BMAD 1.5a-1.5d diagnosis relied heavily on logs)

2. **Consistent Logger Pattern**: Using `get_logger(__name__)` provides clear log source attribution

3. **Future-Proofing**: JSON format enables easy integration with log aggregation platforms (Epic 6 monitoring)

### Knowledge Base

**Recommended Pattern for Epic 2+**:
```python
from shared.logging_config import get_logger

logger = get_logger(__name__)

# Log important operations
logger.info(f"Processing customer {customer_id}")

# Log errors with context
try:
    result = await some_operation()
except Exception as e:
    logger.error(f"Operation failed: {e}", exc_info=True)
    raise
```

**Log Message Guidelines**:
- Include relevant IDs (conversation_id, customer_id, phone)
- Use f-strings for readability
- Add `exc_info=True` for ERROR logs with exceptions
- Avoid logging sensitive data (passwords, tokens, full credit cards)

### Testing Strategy

**Current State**: No unit tests for logging (acceptable for infrastructure code)

**Epic 7 Consideration**: Add integration test that validates log format:
```python
def test_log_format():
    """Verify logs are valid JSON with required fields."""
    logger = get_logger("test")
    with captured_logs() as logs:
        logger.info("Test message")
        log_data = json.loads(logs[0])
        assert "timestamp" in log_data
        assert "level" in log_data
        assert log_data["level"] == "INFO"
```

### Related Issues

- **Epic 6 Story 6.4** (Monitoring): Logs ready for aggregation
- **BMAD 1.5a-1.5d**: All relied on logs for debugging
- **Production Deployment**: Consider log rotation, retention policies

### Prevention

**Going Forward**:
- Document logging strategy in Architecture document (added in this realignment)
- Add logging guidelines to `docs/architecture/coding-standards.md`
- Consider log level environment variable (e.g., `LOG_LEVEL=DEBUG` for local dev)

---

**Resolution Time**: N/A (implemented organically during Epic 1)
**Related Files**: `shared/logging_config.py`, all `*.py` files with `get_logger(__name__)`
**Impact**: Positive - Excellent debugging capability, production-ready logging
**Epic 2+ Readiness**: ✅ Ready, maintain pattern

**References**:
- Python logging best practices: https://docs.python.org/3/howto/logging.html
- JSON logging rationale: https://www.structlog.org/en/stable/why.html
